---
permalink: /glb2022
title: "Workshop on Graph Learning Benchmarks <br>(GLB 2022)"
excerpt: Apr. 26, 2022, Virtual
browser-title: "GLB 2022"
masthead-title: "GLB 2022"
masthead-subtitle: "@TheWebConf 2022"
masthead-url: "/"
layout: splash
author_profile: false
header:
    overlay_color: "#000"
    overlay_filter: "0.5"
    overlay_image: /assets/images/glb-bg.jpg
organizers: # Not ready yet
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
panelists:
    - image_path: /assets/images/glb2022/xin.png
      alt: "Xin Luna Dong"
      excerpt: >
        **Xin Luna Dong**<br>
        Meta
      bio: >
        Xin Luna Dong is the Head Scientist at Facebook AR/VR Assistant. Prior to joining Facebook, she was a Senior Principal Scientist at Amazon, leading the efforts of constructing Amazon Product Knowledge Graph, and before that one of the major contributors to the Google Knowledge Vault project, and has led the Knowledge-based Trust project, which is called the “Google Truth Machine” by Washington’s Post. She has co-authored books "Machine Knowledge: Creation and Curation of Comprehensive Knowledge Bases" and “Big Data Integration”, was awarded ACM Distinguished Member, and VLDB Early Career Research Contribution Award for “Advancing the state of the art of knowledge fusion”. She serves in the VLDB endowment and PVLDB advisory committee, and is a PC co-chair for KDD'2022 ADS track, WSDM 2022, VLDB 2021, and Sigmod 2018.
    
    - image_path: /assets/images/glb2022/petar.jpg
      alt: "Petar Veličković"
      excerpt: >
        **Petar Veličković**<br>
        DeepMind & University of Cambridge
      bio: >
        Petar Veličković is a Staff Research Scientist at DeepMind, Affiliated Lecturer at the University of Cambridge, and an Associate of Clare Hall, Cambridge. He holds a PhD in Computer Science from the University of Cambridge (Trinity College), obtained under the supervision of Pietro Liò. Petar's research concerns geometric deep learning—devising neural network architectures that respect the invariances and symmetries in data (a topic he's co-written a proto-book about). For his contributions to the area, Petar is recognised as an ELLIS Scholar in the Geometric Deep Learning Program. Within this area, Petar focusses on graph representation learning and its applications in algorithmic reasoning and computational biology. In particular, he is the first author of Graph Attention Networks—a popular convolutional layer for graphs—and Deep Graph Infomax—a popular self-supervised learning pipeline for graphs (featured in ZDNet). Petar's research has been used in substantially improving the travel-time predictions in Google Maps (featured in the CNBC, Endgadget, VentureBeat, CNET, the Verge and ZDNet), and guiding the intuition of mathematicians towards new top-tier theorems and conjectures (featured in Nature, New Scientist, The Independent, Sky News, The Sunday Times and The Conversation).
      
    - image_path: /assets/images/glb2022/minjie.png
      alt: "Minjie Wang"
      excerpt: >
        **Minjie Wang**<br>
        Amazon
      bio: >
        Dr. Minjie Wang is currently a senior applied scientist in Amazon AI Shanghai Lab. He obtained his Ph.D. degree from New York University. His research focus is the interdisciplinary area of machine learning and system including building deep learning systems with high usability and performance, applying machine learning in system optimization. He is also an open-source enthusiast; founder and major contributor of well known open source projects such as MXNet, MinPy and Deep Graph Library (DGL).

    - image_path: /assets/images/glb2022/rose.png
      alt: "Rose Yu"
      excerpt: >
        **Rose Yu**<br>
        University of California, San Diego
    
keynote: 
    - image_path: /assets/images/glb2022/michael.jpg
      alt: "Michael Bronstein"
      title: "Michael Bronstein"
      excerpt: |
        ***University of Oxford & Twitter*** <br>
        **Graph Neural Networks: Trends and Open Problems**

      abstract: >
        Graph Neural Networks (GNNs) have become one of the hottest topics 
        in machine learning research due to their applicability across a broad range of fields. 
        In this talk, I will overview the recent trends and open problems in GNNs and their applications. 
      
      bio: >
        Michael Bronstein is the DeepMind Professor of AI at the University of Oxford and Head of Graph 
        Learning Research at Twitter. He was previously a professor at Imperial College London and held 
        visiting appointments at Stanford, MIT, and Harvard, and has also been affiliated with three Institutes 
        for Advanced Study (at TUM as a Rudolf Diesel Fellow (2017-2019), at Harvard as a Radcliffe fellow 
        (2017-2018), and at Princeton as a short-time scholar (2020)). Michael received his PhD from the Technion 
        in 2007. He is the recipient of the Royal Society Wolfson Research Merit Award, Royal Academy of Engineering
        Silver Medal, five ERC grants, two Google Faculty Research Awards, and two Amazon AWS ML Research Awards. 
        He is a Member of the Academia Europaea, Fellow of IEEE, IAPR, BCS, and ELLIS, ACM Distinguished Speaker,
        and World Economic Forum Young Scientist. In addition to his academic career, Michael is a serial 
        entrepreneur and founder of multiple startup companies, including Novafora, Invision (acquired by Intel in 
        2012), Videocites, and Fabula AI (acquired by Twitter in 2019).
      
      spaces: true
    
    - image_path: assets/images/glb2022/stephan.jpg
      alt: "Stephan Günnemann"
      title: "Stephan Günnemann"
      excerpt: |
        ***Technical University of Munich*** <br>
        **Graph Neural Networks for Molecular Systems - Methods and Benchmarks**

      abstract: >
        Effectively predicting molecular interactions has the 
        potential to accelerate molecular dynamics by multiple orders of 
        magnitude and thus revolutionize chemical simulations. Graph neural 
        networks (GNNs) have recently shown great successes for this task. In 
        this talk, I present recent advances in GNNs for molecular systems 
        specifically incorporating the aspect of directionality. Moreover, I 
        will shed light on current evaluation practices and potential 
        limitations in generalization performance of GNNs for diverse molecular 
        systems. I will highlight aspects of
        complexity in which many datasets are lacking and discuss novel 
        benchmark datasets.
      
      bio: >
        Stephan Günnemann is a Professor at the Department of Informatics, 
        Technical University of Munich and Director of the Munich Data Science 
        Institute. His main research focuses on reliable machine learning for 
        graphs and temporal data. Prof. Günnemann is particularly interested in 
        graph neural networks and their application for, e.g., molecular 
        modelling. His works on subspace clustering on graphs as well as 
        adversarial robustness of graph neural networks have received the best 
        research paper awards at ECML-PKDD and KDD.
        Stephan acquired his doctoral degree at RWTH Aachen University, Germany 
        in the field of computer science. From 2012 to 2015 he was an associate 
        of Carnegie Mellon University, USA. Stephan has received a Google 
        Faculty Research Award and is a Junior-Fellow of the German Computer 
        Science Society.
      
      spaces: true

    - image_path: /assets/images/glb2022/tina.png
      alt: "Tina Eliassi-Rad"
      title: "Tina Eliassi-Rad"
      excerpt: |
        ***Northeastern University*** <br>
        **The Why, How, and When of Representations for Complex Systems**
      abstract: >
        The theme of the 2021 Nobel Prize in Physics was the study of complex systems. At the most basic level, complex systems consist of units and their interactions (i.e., graph structures). In this talk, I will describe each step of a data analysis pipeline suitable for the study of complex systems: from the system dependencies that can manifest themselves in different flavors (temporal, subset, and spatial) to the common mathematical representations (such as graphs, simplicial complexes, and hypergraphs), their underlying assumptions, and the dependencies they encode. I will discuss the mathematical relationships between representations and explain how information can be lost (or imputed) when we convert data from one representation to another. I will use examples to highlight the importance of dependencies and careful choice of representations and algorithms when studying complex systems. The main message of the talk is that there is no perfect way to analyze a complex system, and that modeling decisions made when examining a data set from one system are not necessarily transferable to another system, or even to another data set from the same system. Yet, I see many studies apply certain pipelines for seemingly no other reason than because they are common in a particular field. Instead, I recommend evaluating and studying each new complex system and dataset individually and questioning each assumption and modeling decision. 
        
        
        This talk is based on the following paper: Leo Torres, Ann Sizemore Blevins, Danielle S. Bassett, Tina Eliassi-Rad: The Why, How, and When of Representations for Complex Systems. SIAM Review 63(3): 435-485 (2021).
      
      bio: >
        Tina Eliassi-Rad is a Professor of Computer Science at Northeastern University. She is also a core faculty at Northeastern's Network Science Institute and Institute for Experiential AI. In addition, she is an external faculty at Santa Fe Institute and Vermont Complex Systems Center. Tina’s research is at the intersection of data mining, machine learning, and network science. Her work has been applied to personalized search on the World-Wide Web, statistical indices of large-scale scientific simulation data, fraud detection, mobile ad targeting, cyber situational awareness, and ethics in machine learning. Tina's algorithms have been incorporated into systems used by governments, industry, and open-source software. Tina received an Outstanding Mentor Award from the Office of Science at the US Department of Energy in 2010; became a Fellow of the ISI Foundation (Turin, Italy) in 2019; and was named one of the 100 Brilliant Women in AI Ethics for 2021.

      spaces: true
---

{% capture notice-text %}
**Update on Feb 27, 2022: We decided to extend the submission deadline for two weeks to Mar 14.** We are deeply aware of the chaos happening in the world right now. We are absolutely against the war, and our hearts go out to all people affected by the war, especially our Ukrainian and European colleagues. We hope the extension could help accommodate people who need more time to take care of themselves and their loved ones. Hope everyone stays safe in this difficult time. 
{% endcapture %}

<!-- <div class="notice--info">
  <!-- <h4 class="no_toc">Notice Headline:</h4> ~~>
  {{ notice-text | markdownify }}
</div> -->

<script>
if (!sessionStorage.getItem('timezone')) {
  var tz = jstz.determine() || 'UTC';
  sessionStorage.setItem('timezone', tz.name());
}
var currTz = sessionStorage.getItem('timezone');
var startTime = moment("2022-04-26T08:45:00Z");
var tzTime = startTime.tz(currTz)
</script>

# Overview

GLB 2022 is the second edition of the Workshop of the Graph Learning Benchmarks, encouraged by the success of [GLB 2021](/glb2021). 
Inspired by the conference tracks in the computer vision and natural language processing communities that are dedicated to establishing new benchmark datasets and tasks,
we call for contributions that establish novel ML tasks on novel graph-structured data which have the potential to 
(i) identifying systematic failure modes of existing GNNs and providing new technical challenges for the development of new models which highlight diverse future directions, 
(ii) raising the attention of the synergy of graph learning, and
(iii) crowdsourcing benchmark datasets for various tasks of graph ML.
GLB 2022 will be a **virtual** and **non-archival** workshop.

<!-- Inspired by the conference tracks in the computer vision and natural language processing communities that are dedicated to establishing new benchmark datasets and tasks, 
we call for contributions that introduce novel ML tasks or novel graph-structured data which have the potential to 
(i) help understand the performance and limitations of graph representation models on diverse sets of problems and 
(ii) support benchmark evaluations for various models. -->

Our previous call for papers can be found [here](/glb2022/call-for-papers). 

# Registration
Please [register for The Web Conference 2022](https://www2022.thewebconf.org/registration/) to join our workshop. A "Monday & Tuesday only" access (100 €) would be sufficient for joining us, including for the authors who are presenting. We do not require the authors to register with the "Author" pass (250 € / 300 €). 


# Schedule

All the time listed below are in the time of Lyon, France (Central European Summer Time, UTC+2) in 24-hour clock. The workshop will start at Apr 26, 2022 10:45 CEST<span id="viewerTime"></span>.

| Time (UTC+2) | Agenda |
| ----------------- | ------------ |
| **10:45-10:50**    | **Opening remarks** |
| **10:50-11:40**    | **[Keynote by Michael Bronstein](#Michael+Bronstein) (50 min)**: <br> Graph Neural Networks: Trends and Open Problems |
| **11:40-12:40**    | **Paper Presentation - Session 1 (60 min)** |
| **12:40-14:00**    | **Lunch Break (80 min)** |
| **14:00-14:50**    | **[Keynote by Stephan Günnemann](#Stephan+Günnemann) (50 min)**: <br> Graph Neural Networks for Molecular Systems - Methods and Benchmarks |
| **14:50-15:30**    | **Paper Presentation - Session 2 (40 min)** |
| **15:30-15:45**    | **Break (15 min)**|
| **15:45-16:35**    | **[Keynote by Tina Eliassi-Rad](#Tina+Eliassi-Rad) (50 min)**: <br> The Why, How, and When of Representations for Complex Systems |
| **16:35-17:15**    | **Paper Presentation - Session 3 (40 min)** |
| **17:15-18:15**    | **Break (Plenary Talk at TheWebConf) (60 min)** |
| **18:15-19:15**    | **[Panel Discussion](#panelists) (60 min)** |
| **19:15-19:30**    | **Closing Remarks** |

<script>
  document.getElementById("viewerTime").innerHTML = " (" + tzTime.format('MMM DD h:mma z') + ")"
</script>

# Keynote Speakers

{% include feature_row id="keynote" type="left" %}
<!-- {% include feature_row id="invited-talk" type="left" %} -->

# Panelists
{% include feature_row id="panelists" %}

# Accepted Papers
<ul>
{% for pubitem in site.data.papers2022 %}
    <li> {{ pubitem.title | markdownify | remove: '<p>' | remove: '</p>' | strip }} <br>
    <div class="small">
    <i> {{ pubitem.authors | markdownify | remove: '<p>' | remove: '</p>' | strip }} </i> 
    </div>
    {% if pubitem.abstract %} 
    <a class="btn btn--small btn--info collapsible">Abstract</a> 
    <div class="btn-content small">
        <b>Abstract</b>: {{ pubitem.abstract }}
    </div>
    {% endif %}
    {% if pubitem.PDF %} <a href="{{ pubitem.PDF }}" class="btn btn--small btn--info">PDF</a>{% endif %}
    {% if pubitem.code %} <a href="{{ pubitem.code }}" class="btn btn--small btn--info">
    {% if pubitem.new_dataset %} Code & Datasets {% else %} Code {% endif %} </a>{% endif %}
    </li>
{% endfor %}
</ul>

# Organizers
{% capture organizers %}
- **[Jiaqi Ma](http://www.jiaqima.com/)** (University of Michigan)
- **[Jiong Zhu](https://www.jiongzhu.net/)** (University of Michigan)
- **[Anton Tsitsulin](http://tsitsul.in/)** (Google Research)
- **[Marinka Zitnik](https://zitniklab.hms.harvard.edu/bio/)** (Harvard University)
{% endcapture %}

<div class="small">
{{ organizers | markdownify }}
</div>
<!-- {% include feature_row id="organizers" %} -->

# Advisory Board
{% capture advisory-board %}
- **[Yuxiao Dong](https://ericdongyx.github.io/)** (Facebook AI)
- **[Danai Koutra](https://web.eecs.umich.edu/~dkoutra/)** (University of Michigan)
- **[Qiaozhu Mei](http://www-personal.umich.edu/~qmei/)** (University of Michigan)
{% endcapture %}

<div class="small">
{{ advisory-board | markdownify }}
</div>

# Program Committee
<div class="small row-two-columns">
<div class="column-half">
<ul>
{% for people in site.data.pc-members2022 limit:12 %}
<li>{{ people | markdownify | remove: '<p>' | remove: '</p>' | strip }} </li>
{% endfor %}
</ul>
</div>
<div class="column-half">
<ul>
{% for people in site.data.pc-members2022 offset:12 %}
<li>{{ people | markdownify | remove: '<p>' | remove: '</p>' | strip }} </li>
{% endfor %}
</ul>
</div>
</div>

<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
    coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
        content.style.display = "none";
        } else {
        content.style.display = "block";
        }
    });
    }
</script>
