---
permalink: /glb2022
title: "Workshop on Graph Learning Benchmarks <br>(GLB 2022)"
excerpt: Apr. 26, 2022, Virtual
browser-title: "GLB 2022"
masthead-title: "GLB 2022"
masthead-subtitle: "@TheWebConf 2022"
masthead-url: "/"
layout: splash
author_profile: false
header:
    overlay_color: "#000"
    overlay_filter: "0.5"
    overlay_image: /assets/images/glb-bg.jpg
organizers: # Not ready yet
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
    - image_path: /assets/images/danai.jpg
      alt: "Danai Koutra"
      excerpt: "**Danai Koutra**"
panelists:
    - image_path: /assets/images/guennemann.jpg
      alt: "Stephan Günnemann"
      excerpt: >
        **Stephan Günnemann**<br>
        Technical University of Munich
    - image_path: /assets/images/yizhou.jpg
      alt: "Yizhou Sun"
      excerpt: >
        **Yizhou Sun**<br>
        University of California, Los Angeles
    - image_path: /assets/images/Jie.jpg
      alt: "Jie Tang"
      excerpt: >
        **Jie Tang**<br>
        Tsinghua University

keynote: # Not ready yet
    - image_path: https://www.cs.ox.ac.uk/files/13446//michael%20-%20passport.jpg
      alt: "Michael Bronstein"
      title: "Michael Bronstein"
      excerpt: |
        ***University of Oxford & Twitter*** <br>
        **Graph Neural Networks: Trends and Open Problems**

      abstract: >
        Graph Neural Networks (GNNs) have become one of the hottest topics 
        in machine learning research due to their applicability across a broad range of fields. 
        In this talk, I will overview the recent trends and open problems in GNNs and their applications. 
      
      bio: >
        Michael Bronstein is the DeepMind Professor of AI at the University of Oxford and Head of Graph 
        Learning Research at Twitter. He was previously a professor at Imperial College London and held 
        visiting appointments at Stanford, MIT, and Harvard, and has also been affiliated with three Institutes 
        for Advanced Study (at TUM as a Rudolf Diesel Fellow (2017-2019), at Harvard as a Radcliffe fellow 
        (2017-2018), and at Princeton as a short-time scholar (2020)). Michael received his PhD from the Technion 
        in 2007. He is the recipient of the Royal Society Wolfson Research Merit Award, Royal Academy of Engineering
        Silver Medal, five ERC grants, two Google Faculty Research Awards, and two Amazon AWS ML Research Awards. 
        He is a Member of the Academia Europaea, Fellow of IEEE, IAPR, BCS, and ELLIS, ACM Distinguished Speaker,
        and World Economic Forum Young Scientist. In addition to his academic career, Michael is a serial 
        entrepreneur and founder of multiple startup companies, including Novafora, Invision (acquired by Intel in 
        2012), Videocites, and Fabula AI (acquired by Twitter in 2019).
      
      spaces: true
    
    - image_path: https://www.in.tum.de/fileadmin/_processed_/c/6/csm_guennemann3_904c51d801.jpg
      alt: "Stephan Günnemann"
      title: "Stephan Günnemann"
      excerpt: |
        ***Technical University of Munich*** <br>
        **Graph Neural Networks for Molecular Systems - Methods and Benchmarks**

      abstract: >
        Effectively predicting molecular interactions has the 
        potential to accelerate molecular dynamics by multiple orders of 
        magnitude and thus revolutionize chemical simulations. Graph neural 
        networks (GNNs) have recently shown great successes for this task. In 
        this talk, I present recent advances in GNNs for molecular systems 
        specifically incorporating the aspect of directionality. Moreover, I 
        will shed light on current evaluation practices and potential 
        limitations in generalization performance of GNNs for diverse molecular 
        systems. I will highlight aspects of
        complexity in which many datasets are lacking and discuss novel 
        benchmark datasets.
      
      bio: >
        Stephan Günnemann is a Professor at the Department of Informatics, 
        Technical University of Munich and Director of the Munich Data Science 
        Institute. His main research focuses on reliable machine learning for 
        graphs and temporal data. Prof. Günnemann is particularly interested in 
        graph neural networks and their application for, e.g., molecular 
        modelling. His works on subspace clustering on graphs as well as 
        adversarial robustness of graph neural networks have received the best 
        research paper awards at ECML-PKDD and KDD.
        Stephan acquired his doctoral degree at RWTH Aachen University, Germany 
        in the field of computer science. From 2012 to 2015 he was an associate 
        of Carnegie Mellon University, USA. Stephan has received a Google 
        Faculty Research Award and is a Junior-Fellow of the German Computer 
        Science Society.
      
      spaces: true

    - image_path: http://eliassi.org/tina2016highres.png
      alt: "Tina Eliassi-Rad"
      title: "Tina Eliassi-Rad"
      excerpt: |
        ***Northeastern University*** <br>
        **The Why, How, and When of Representations for Complex Systems**
      abstract: >
        The theme of the 2021 Nobel Prize in Physics was the study of complex systems. At the most basic level, complex systems consist of units and their interactions (i.e., graph structures). In this talk, I will describe each step of a data analysis pipeline suitable for the study of complex systems: from the system dependencies that can manifest themselves in different flavors (temporal, subset, and spatial) to the common mathematical representations (such as graphs, simplicial complexes, and hypergraphs), their underlying assumptions, and the dependencies they encode. I will discuss the mathematical relationships between representations and explain how information can be lost (or imputed) when we convert data from one representation to another. I will use examples to highlight the importance of dependencies and careful choice of representations and algorithms when studying complex systems. The main message of the talk is that there is no perfect way to analyze a complex system, and that modeling decisions made when examining a data set from one system are not necessarily transferable to another system, or even to another data set from the same system. Yet, I see many studies apply certain pipelines for seemingly no other reason than because they are common in a particular field. Instead, I recommend evaluating and studying each new complex system and dataset individually and questioning each assumption and modeling decision. 
        
        
        This talk is based on the following paper: Leo Torres, Ann Sizemore Blevins, Danielle S. Bassett, Tina Eliassi-Rad: The Why, How, and When of Representations for Complex Systems. SIAM Review 63(3): 435-485 (2021).
      
      bio: >
        Tina Eliassi-Rad is a Professor of Computer Science at Northeastern University. She is also a core faculty at Northeastern's Network Science Institute and Institute for Experiential AI. In addition, she is an external faculty at Santa Fe Institute and Vermont Complex Systems Center. Tina’s research is at the intersection of data mining, machine learning, and network science. Her work has been applied to personalized search on the World-Wide Web, statistical indices of large-scale scientific simulation data, fraud detection, mobile ad targeting, cyber situational awareness, and ethics in machine learning. Tina's algorithms have been incorporated into systems used by governments, industry, and open-source software. Tina received an Outstanding Mentor Award from the Office of Science at the US Department of Energy in 2010; became a Fellow of the ISI Foundation (Turin, Italy) in 2019; and was named one of the 100 Brilliant Women in AI Ethics for 2021.

      spaces: true
---

{% capture notice-text %}
**Update on Feb 27, 2022: We decided to extend the submission deadline for two weeks to Mar 14.** We are deeply aware of the chaos happening in the world right now. We are absolutely against the war, and our hearts go out to all people affected by the war, especially our Ukrainian and European colleagues. We hope the extension could help accommodate people who need more time to take care of themselves and their loved ones. Hope everyone stays safe in this difficult time. 
{% endcapture %}

<!-- <div class="notice--info">
  <!-- <h4 class="no_toc">Notice Headline:</h4> ~~>
  {{ notice-text | markdownify }}
</div> -->

<script>
if (!sessionStorage.getItem('timezone')) {
  var tz = jstz.determine() || 'UTC';
  sessionStorage.setItem('timezone', tz.name());
}
var currTz = sessionStorage.getItem('timezone');
var startTime = moment("2021-04-16T13:00:00Z");
var tzTime = startTime.tz(currTz)
</script>

# Overview

GLB 2022 is the second edition of the Workshop of the Graph Learning Benchmarks, encouraged by the success of [GLB 2021](/glb2021). 
Inspired by the conference tracks in the computer vision and natural language processing communities that are dedicated to establishing new benchmark datasets and tasks,
we call for contributions that establish novel ML tasks on novel graph-structured data which have the potential to 
(i) identifying systematic failure modes of existing GNNs and providing new technical challenges for the development of new models which highlight diverse future directions, 
(ii) raising the attention of the synergy of graph learning, and
(iii) crowdsourcing benchmark datasets for various tasks of graph ML.
GLB 2022 will be a **virtual** and **non-archival** workshop.

<!-- Inspired by the conference tracks in the computer vision and natural language processing communities that are dedicated to establishing new benchmark datasets and tasks, 
we call for contributions that introduce novel ML tasks or novel graph-structured data which have the potential to 
(i) help understand the performance and limitations of graph representation models on diverse sets of problems and 
(ii) support benchmark evaluations for various models. -->

Our previous call for papers can be found [here](./call-for-papers). 

<!-- # Schedule

All the time listed below are in Ljubljana time (Central European Summer Time, UTC+2). The workshop will start at Apr 16, 2021 3:00pm CEST<span id="viewerTime"></span>.

| Time (UTC+2) | Agenda |
| ----------------- | ------------ |
| **3:00-3:10pm**    | **Opening remarks** |
| **3:10-3:30pm**    | **[Invited talk by Leman Akoglu](#Leman+Akoglu) (20 min)**: <br> On Using Classification Datasets to Evaluate Graph Outlier Detection: Peculiar Observations and New Insights |
| **3:30-4:00pm**    | **Contributed talks (12 min + 3-min Q&A for each):**<br>\- Reproducible Evaluations of Network Representation Learning Models Using EvalNE<br>\- Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification |
| **4:00-4:05pm**    | **Break (5 min)** |
| **4:05-4:40pm**    | **Spotlight talks (11 x 3 min)** |
| **4:40-5:30pm**    | **Interactive poster session & Break (50 min)** |
| **5:30-6:25pm**    | **[Panel discussion](#panelists) (55 min):<br>Stephan Günnemann, Yizhou Sun, Jie Tang**|
| **6:25-6:30pm**    | **Break (5 min)** |
| **6:30-7:10pm**    | **[Keynote by Jure Leskovec](#Jure+Leskovec) (40 min)**: <br> Open Graph Benchmark Large-Scale Challenge |
| **7:10-7:20pm**    | **Closing remarks** | -->

<script>
  document.getElementById("viewerTime").innerHTML = " (" + tzTime.format('MMM DD h:mma z') + ")"
</script>

# Keynote Speakers

{% include feature_row id="keynote" type="left" %}
<!-- {% include feature_row id="invited-talk" type="left" %} -->

<!-- # Panelists
{% include feature_row id="panelists" %} -->

<!-- # Accepted Papers
<ul>
{% for pubitem in site.data.papers %}
    <li> {{ pubitem.title | markdownify | remove: '<p>' | remove: '</p>' | strip }} <br>
    <div class="small">
    <i> {{ pubitem.authors | markdownify | remove: '<p>' | remove: '</p>' | strip }} </i> 
    </div>
    {% if pubitem.abstract %} 
    <a class="btn btn--small btn--info collapsible">Abstract</a> 
    <div class="btn-content small">
        <b>Abstract</b>: {{ pubitem.abstract }}
    </div>
    {% endif %}
    {% if pubitem.PDF %} <a href="{{ pubitem.PDF }}" class="btn btn--small btn--info">PDF</a>{% endif %}
    {% if pubitem.code %} <a href="{{ pubitem.code }}" class="btn btn--small btn--info">
    {% if pubitem.new_dataset %} Code & Datasets {% else %} Code {% endif %} </a>{% endif %}
    </li>
{% endfor %}
</ul> -->

# Organizers
{% capture organizers %}
- **[Jiaqi Ma](http://www.jiaqima.com/)** (University of Michigan)
- **[Jiong Zhu](https://www.jiongzhu.net/)** (University of Michigan)
- **[Anton Tsitsulin](http://tsitsul.in/)** (Google Research)
- **[Marinka Zitnik](https://zitniklab.hms.harvard.edu/bio/)** (Harvard University)
{% endcapture %}

<div class="small">
{{ organizers | markdownify }}
</div>
<!-- {% include feature_row id="organizers" %} -->

# Advisory Board
{% capture advisory-board %}
- **[Yuxiao Dong](https://ericdongyx.github.io/)** (Facebook AI)
- **[Danai Koutra](https://web.eecs.umich.edu/~dkoutra/)** (University of Michigan)
- **[Qiaozhu Mei](http://www-personal.umich.edu/~qmei/)** (University of Michigan)
{% endcapture %}

<div class="small">
{{ advisory-board | markdownify }}
</div>

<!-- # Program Committee
<div class="small row-two-columns">
<div class="column-half">
<ul>
{% for people in site.data.pc-members limit:10 %}
<li>{{ people | markdownify | remove: '<p>' | remove: '</p>' | strip }} </li>
{% endfor %}
</ul>
</div>
<div class="column-half">
<ul>
{% for people in site.data.pc-members offset:10 %}
<li>{{ people | markdownify | remove: '<p>' | remove: '</p>' | strip }} </li>
{% endfor %}
</ul>
</div>
</div> -->

<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
    coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
        content.style.display = "none";
        } else {
        content.style.display = "block";
        }
    });
    }
</script>
