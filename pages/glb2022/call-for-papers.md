---
permalink: /glb2022/call-for-papers
title: "Call for Papers - GLB 2022"
layout: splash
browser-title: "GLB 2022"
masthead-title: "GLB 2022"
masthead-subtitle: "@TheWebConf 2022"
masthead-url: "/"
# classes: wide
author_profile: false
header:
    overlay_color: "#000"
    overlay_filter: "0.5"
    overlay_image: /assets/images/glb-bg.jpg
---

{% capture notice-text %}
**You are viewing the archived site for GLB 2022.** To learn more on the latest edition of the workshop, [click here](/).
{% endcapture %}

<!-- <div class="notice--warning">
  <!-- <h4 class="no_toc">Notice Headline:</h4> ~~>
  {{ notice-text | markdownify }}
</div> -->


We especially (but not exclusively) call for submissions which will contribute to at least one of the following:

- **Real-World Datasets**: Novel real-world graph-structured datasets---especially large-scale, application-oriented, and publicly accessible datasets. 
- **Synthetic Datasets** (*New*): Synthetic graph-structured datasets that are well-supported by graph theory, network science, or empirical studies, and can be used to reveal limitations of existing graph learning methods.
- **Software Packages**: Software packages which enable streamlined benchmarking large-scale online graphs, crawling or crowdsourcing of graph data, and generation of realistic synthetic graphs. 
- **Tasks**: New learning tasks and applications on different types of graphs, at different levels (e.g., node, edge, and (sub)graph), with a special focus on real-world and industry-oriented problems.
- **Metrics**: New evaluation procedures and metrics of graph learning associated with the various tasks and datasets. 
- **Benchmarks**: Works benchmarking multiple existing GNNs on non-trivial tasks and datasets. We explicitly encourage works that reveal limitations of existing models or optimize matches between network designs and problems. 
- **Task Taxonomy** (*New*): Discussions towards a more comprehensive and fine-grained taxonomy of graph learning tasks.

The acceptance of the contributed papers will be decided on the meaningfulness of the established graph learning tasks or datasets and their potential of being formalized into new benchmarks, rather than the performance of ML models (old or new) on these tasks. We particularly welcome contributions of **negative results** of popular, state-of-the-art models on a new task or dataset, as these provide novel insights to the community’s understanding of the meta-knowledge of graph ML. 

## Important Dates
- **Submission deadline**: ~~Feb 28, 2022~~ Mar 14, 2022 (Anywhere on Earth)
- **Acceptance notification**: ~~Mar 21, 2022~~ Apr 4, 2022
- **Camera-ready version due**: ~~Apr 4, 2022~~ Apr 18, 2022
<!-- - **Workshop**: Apr. 26, 2022 -->

## Submission
Abstracts and papers can be submitted through CMT: <br>
[https://cmt3.research.microsoft.com/GLB2022](https://cmt3.research.microsoft.com/GLB2022)

## Format

- For unpublished submissions, please submit a paper no longer than *4 pages* (excluding references and the appendices) using [the ACM “sigconf” LaTeX template](https://www.overleaf.com/latex/templates/association-for-computing-machinery-acm-sig-proceedings-template/bmvfhcdnxfty) (see [the instruction by the Web Conference 2022](https://www2022.thewebconf.org/cfp/research/)). If your submission includes appendices, it is not necessary to submit the appendices as a separate PDF file.
- This workshop is *non-archival*. Relevant findings that have been recently published are also welcome. For already published submissions, the paper can be submitted in the original format. These submissions will be very lightly reviewed for their relevance to this workshop.
- The submission is single-blinded for the ease of data/code sharing. The reviewers are anonymized but the authors do not need to be anonymized in the submission.
- Authors are *strongly encouraged* to include the corresponding datasets and code as supplementary materials in their submission. For large datasets or repositories, the authors can provide an external link through Github, Google drive, Dropbox, OneDrive, or Box. We limit the choice of storage platforms for security considerations. Please email the organizers if none of the listed platforms works for you.
- If the data cannot be made publicly available, an extra section is required to illustrate how the results of the established benchmark may generalize to other graph data.