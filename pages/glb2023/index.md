---
permalink: /glb2023
title: "Workshop on Graph Learning Benchmarks <br>(GLB 2023)"
excerpt: Aug. 6, 2023 - Long Beach, CA, USA <br> Held in conjunction with <a href="https://kdd.org/kdd2023/">KDD 2023</a>
browser-title: "GLB 2023"
masthead-title: "GLB 2023"
masthead-subtitle: "@KDD 2023"
masthead-url: "/"
layout: splash
author_profile: false
header:
    overlay_color: "#000"
    overlay_filter: "0.5"
    overlay_image: /assets/images/glb-bg.jpg
navigation:
  - title: "CfP"
    url: /glb2023/call-for-papers
  # - title: "Important Dates"
  #   url: /glb2023#important-dates
  # - title: "Submission"
  #   url: /glb2023#submission
  - title: "Schedule"
    url: /glb2023#schedule
  - title: "Keynotes"
    url: /glb2023#keynote-speakers
  - title: "Panelists"
    url: /glb2023#panelists
  # - title: "Accepted Papers"
  #   url: /glb2022#accepted-papers
  - title: "Organization"
    url: /glb2023#organizers
  - title: "Past Editions"
    url: /all-editions

keynote: 
    - image_path: /assets/images/glb2023/Bresson.jpg
      alt: "Xavier Bresson"
      title: "Xavier Bresson"
      excerpt: |
        ***National University of Singapore*** <br>

      # abstract: >
      #   (TBD)
      
      bio: >
        Xavier Bresson (PhD 2005, EPFL, Switzerland) is Associate Professor in Computer Science at NUS, Singapore. He is a leading researcher in the field of Graph Deep Learning, a new framework that combines graph theory and deep learning techniques to tackle complex data domains in natural language processing, computer vision, combinatorial optimization, quantum chemistry, physics, neuroscience, genetics and social networks. In 2016, he received the highly competitive Singaporean NRF Fellowship of $2.5M to develop these deep learning techniques. He was also awarded several research grants in the U.S. and Hong Kong. As a leading researcher in the field, he has published more than 60 peer-reviewed papers in the leading journals and conference proceedings in machine learning, including articles in NeurIPS, ICML, ICLR, CVPR, JMLR. He has organized several international workshops and tutorials on AI and deep learning in collaboration with Facebook, NYU and Imperial such as the 2019 and 2018 UCLA workshops, the 2017 CVPR tutorial and the 2017 NeurIPS tutorial. He has been teaching undergraduate, graduate and industrial courses in AI and deep learning since 2014 at EPFL (Switzerland), NTU (Singapore) and UCLA (U.S.).
      
      spaces: true
    
    - image_path: assets/images/glb2023/Sun.jpg
      alt: "Jimeng Sun"
      title: "Jimeng Sun"
      excerpt: |
        ***University of Illinois, Urbana-Champaign*** <br>

      # abstract: >
      #   (TBD)
      
      bio: >
        Jimeng Sun is the Health Innovation Professor at Computer Science Department and Carle's Illinois College of Medicine at University of Illinois, Urbana-Champaign. Previously, he was with the College of Computing, Georgia Institute of Technology. His research interest include artificial intelligence for healthcare, deep learning for drug discovery, clinical trial optimization, computational phenotyping, clinical predictive modeling, treatment recommendation, and health monitoring.
      
      spaces: true

    - image_path: /assets/images/glb2023/YSun.jpg
      alt: "Yizhou Sun"
      title: "Yizhou Sun"
      excerpt: |
        ***University of California, Los Angeles*** <br>

      # abstract: >
      #   (TBD)
      
      bio: >
        Yizhou Sun received the PhD degree in computer science from the University of Illinois at Urbana-Champaign in 2012. She is currently an associate professor with the Department of Computer Science, UCLA. She joined UCLA in 2016 after her first position with Northeastern University. She got her early tenure in 2018. She has more than 180 publications in books, journals, and major conferences, and her h-index is 50. Tutorials of her research have been given in many premier conferences. Her research interests include mining graphs/networks, data mining, machine learning, and network science, with a focus on modeling novel problems and proposing scalable algorithms for large-scale, real-world applications. She is a pioneer researcher in mining heterogeneous information network, with a recent focus on deep learning on graphs/networks. She has been an associate editor editor for several major data mining/information system journals, PC chair/vice PC chair for several conferences and workshops, and area chairs/senior PCs for major top conferences in data mining, machine learning, and artificial intelligence. She also was on several award committees, including KDD Best Paper Award, SIGIR Best Paper Award, and KDD Dissertation Award Committee. She was the recipient of the Best Student Paper Award from KDD and BCB, ACM SIGKDD Doctoral Dissertation Award, Yahoo ACE (Academic Career Enhancement) Award, NSF CAREER Award, CS@ILLINOIS Distinguished Educator Award, Amazon Research Awards (twice), and Okawa Foundation Research Award.

      spaces: true

    - image_path: /assets/images/glb2023/AWang.jpg
      alt: "Atlas Wang"
      title: "Atlas Wang"
      excerpt: |
        ***The University of Texas at Austin*** <br>

      # abstract: >
      #   (TBD)
      
      bio: >
        Professor Zhangyang “Atlas” Wang is currently the Jack Kilby/Texas Instruments Endowed Assistant Professor in the Chandra Family Department of Electrical and Computer Engineering at The University of Texas at Austin. He received the Ph.D. degree from the University of Illinois at Urbana–Champaign, under the supervision of Prof. Thomas Huang. He was an Assistant Professor at Texas A&M University from 2017 to 2020. His research interests include machine learning, computer vision, optimization, and their interdisciplinary applications. Most recently, he studies automated machine learning (AutoML), learning to optimize (L2O), robust learning, efficient learning, and graph neural networks.

      spaces: true

    - image_path: /assets/images/glb2023/MJie.png
      alt: "Minjie Wang"
      title: "Minjie Wang"
      excerpt: |
        ***Amazon*** <br>

      # abstract: >
      #   (TBD)
      
      bio: >
        Dr. Minjie Wang is currently a senior applied scientist in Amazon AI Shanghai Lab. He obtained his Ph.D. degree from New York University. His research focus is the interdisciplinary area of machine learning and system including building deep learning systems with high usability and performance, applying machine learning in system optimization. He is also an open-source enthusiast; founder and major contributor of well known open source projects such as MXNet, MinPy and Deep Graph Library (DGL).

      spaces: true

panelists:
    - image_path: /assets/images/glb2023/MGalkin.jpg
      alt: "Michael Galkin"
      excerpt: >
        **Michael Galkin**<br>
        Intel Labs
      bio: >
        Michael Galkin is a Research Scientist at Intel AI Labs working on Graph Machine Learning and Geometric Deep Learning. Previously, Michael was a postdoc at Mila - Quebec AI Institute, working with Will Hamilton, Jian Tang, and Reihaneh Rabbany on various graph learning tasks ranging from reasoning and knowledge graphs to molecular representation learning.
    
    - image_path: /assets/images/glb2023/NShah.jpg
      alt: "Neil Shah"
      excerpt: >
        **Neil Shah**<br>
        Snap Research
      bio: >
        Neil Shah received the Ph.D. degree in computer science from the Department of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA, in 2017. He is a Research Scientist with Snap Inc., Seattle, WA, USA, with interests in data mining, machine learning, and computational social science on online platforms, with special focus on graph-based modeling for user behavior and misbehavior. His work has resulted in 35+ conference and journal publications, in top venues such as KDD, ICDM, WWW, SDM, DSAA, PAKDD, TKDD, and more, including several best-paper awards. He has also served as an organizer, chair, and on program committees at a number of these. He has had previous research experiences with Lawrence Livermore National Laboratory, Livermore, CA, USA; Microsoft Research, Redmond, WA; and Twitch.tv, San Francisco, CA, USA.
      
    - image_path: /assets/images/glb2023/YYan.jpg
      alt: "Yujun Yan"
      excerpt: >
        **Yujun Yan**<br>
        Dartmouth College
      bio: >
        Yujun Yan is an Assistant Professor from the Computer Science Department at Dartmouth College. She obtained her PhD from the University of Michigan, Ann Arbor, in 2022. Her area of specialization is graph-based machine learning, with a particular focus on generalizing graph neural networks to graphs with diverse properties, such as varying levels of heterophily and sizes. Her research on heterophily graphs has received widespread recognition and hundreds of citations. Yujun has published multiple papers at top machine learning and data mining conferences, including NeurIPS, KDD, and the WebConf. Her works have been integrated into the curricula of esteemed institutions such as Stanford University and Northeastern University. During her Ph.D., She completed internships at Microsoft Research in 2018 and 2021, as well as at Google Research in 2019 and 2020. She holds a pending patent with Google.
      
---


<!-- <div class="notice--info">
  <!-- <h4 class="no_toc">Notice Headline:</h4> ~~>
  {{ notice-text | markdownify }}
</div> -->

<script>
if (!sessionStorage.getItem('timezone')) {
  var tz = jstz.determine() || 'UTC';
  sessionStorage.setItem('timezone', tz.name());
}
var currTz = sessionStorage.getItem('timezone');
var startTime = moment("2022-04-26T08:45:00Z");
var tzTime = startTime.tz(currTz)
</script>

# Overview

GLB 2023 is the third edition of the Workshop of the Graph Learning Benchmarks, encouraged by the success of [the previous editions](/all-editions). 
Inspired by the conference tracks in the computer vision and natural language processing communities that are dedicated to establishing new benchmark datasets and tasks,
we call for contributions that establish novel ML tasks on novel graph-structured data which have the potential to
(i) increase the diversity of graph learning benchmarks,
(ii) identify new demands of graph machine learning in general, and 
(iii) gain a better synergy of how concrete techniques perform on these benchmarks. 
We also welcome contributions on data-centric graph learning, such as novel approaches to collect, annotate, clean, augment, and sythesize graph-structured data.

GLB 2023 will be a **non-archival** workshop; we are excited to host this edition **in person** in conjunction with [**KDD 2023**](https://kdd.org/kdd2023/). Please click [here](https://web.cvent.com/event/d8874717-951f-4368-b286-40f3f31cdbc3/summary) for KDD 2023 registration.

<!-- Inspired by the conference tracks in the computer vision and natural language processing communities that are dedicated to establishing new benchmark datasets and tasks, 
we call for contributions that introduce novel ML tasks or novel graph-structured data which have the potential to 
(i) help understand the performance and limitations of graph representation models on diverse sets of problems and 
(ii) support benchmark evaluations for various models. -->

Our previous call for papers can be found [here](/glb2023/call-for-papers).

# Schedule

<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTRMzc0vmmj11ItBZKcHgKIVed9VaePOYvUeueLsOZidKApQmheY0fFLptdCVNhWCQLXPCxfLRxThiA/pubhtml?gid=0&amp;single=true&amp;widget=true&amp;headers=false" width="100%" height="600"></iframe>

# Keynote Speakers
{% include feature_row id="keynote" type="left" %}

# Panelists
{% include feature_row id="panelists" %}

<!-- # Accepted Papers
<ul>
{% for pubitem in site.data.papers2023 %}
    <li> {{ pubitem.title | markdownify | remove: '<p>' | remove: '</p>' | strip }} <br>
    <div class="small">
    <i> {{ pubitem.authors | markdownify | remove: '<p>' | remove: '</p>' | strip }} </i> 
    </div>
    {% if pubitem.abstract %} 
    <a class="btn btn--small btn--info collapsible">Abstract</a> 
    <div class="btn-content small">
        <b>Abstract</b>: {{ pubitem.abstract }}
    </div>
    {% endif %}
    {% if pubitem.PDF %} <a href="{{ pubitem.PDF }}" class="btn btn--small btn--info">PDF</a>{% endif %}
    {% if pubitem.code %} <a href="{{ pubitem.code }}" class="btn btn--small btn--info">
    {% if pubitem.new_dataset %} Code & Datasets {% else %} Code {% endif %} </a>{% endif %}
    </li>
{% endfor %}
</ul> -->

# Organizers
Please contact us through <a target="_blank" href="https://mailhide.io/e/5RV52Tlm">this email address</a> if you have any questions.

{% capture organizers %}
A list of organizers can also be found [here](https://airtable.com/shrwvG9wYqjrbXq0s/tblLXlCDQlpCBK6lR?backgroundColor=purple).
{% endcapture %}

<div class="small">
{{ organizers | markdownify }}
</div>

<style>
    #organizer-wrap { width: 100%; height: 750; padding: 0; overflow: hidden; }
    #organizer-frame { width: 107%; height: 750; background: transparent; border: 1px solid #ccc; }
    #organizer-frame {
        -ms-zoom: 0.93;
        -moz-transform: scale(0.93);
        -moz-transform-origin: 0 0;
        -o-transform: scale(0.93);
        -o-transform-origin: 0 0;
        -webkit-transform: scale(0.93);
        -webkit-transform-origin: 0 0;
    }
</style>
<div id="organizer-wrap">
<iframe id="organizer-frame" class="airtable-embed" src="https://airtable.com/embed/shrwvG9wYqjrbXq0s?backgroundColor=purple" frameborder="0" onmousewheel="" height="750" style="background: transparent; border: 1px solid #ccc;"></iframe>
</div>

<!-- <iframe class="airtable-embed" src="https://airtable.com/embed/shrwvG9wYqjrbXq0s?backgroundColor=purple" frameborder="0" onmousewheel="" width="106%" height="750" style="background: transparent; border: 1px solid #ccc;"></iframe> -->


<!-- # Program Committee
<div class="small row-two-columns">
<div class="column-half">
<ul>
{% for people in site.data.pc-members2022 limit:12 %}
<li>{{ people | markdownify | remove: '<p>' | remove: '</p>' | strip }} </li>
{% endfor %}
</ul>
</div>
<div class="column-half">
<ul>
{% for people in site.data.pc-members2022 offset:12 %}
<li>{{ people | markdownify | remove: '<p>' | remove: '</p>' | strip }} </li>
{% endfor %}
</ul>
</div>
</div>

<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
    coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
        content.style.display = "none";
        } else {
        content.style.display = "block";
        }
    });
    }
</script> -->

<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
    coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
        content.style.display = "none";
        } else {
        content.style.display = "block";
        }
    });
    }
</script>